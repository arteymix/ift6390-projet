{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auteurs:** Guillaume Poirier-Morency et Gabriel Lemyre\n",
    "\n",
    "Chaque modèle est présenté successivement, entraîné et finalement testés selon les meilleurs paramètres obtenus par le processus de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données de salaire est déjà séparé en deux ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_dtype = OrderedDict([('age', 'int'), \n",
    "                            ('workclass', 'category'), \n",
    "                            ('financial_weight', 'int'), \n",
    "                            ('education', 'category'), \n",
    "                            ('education_code', 'int'),\n",
    "                            ('marital_status', 'category'), \n",
    "                            ('occupation', 'category'),\n",
    "                            ('relationship', 'category'),\n",
    "                            ('race', 'category'),\n",
    "                            ('sex', 'category'),\n",
    "                            ('capital_gain', 'int'),\n",
    "                            ('capital_loss', 'int'),\n",
    "                            ('hours_per_week', 'int'),\n",
    "                            ('native_country', 'category'),\n",
    "                            ('target', 'category')])\n",
    "salary_continuous_columns = ['age', 'financial_weight', 'education_code', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "salary_categorical_columns = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
    "salary_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', sep=', ', engine='python', names=salary_dtype.keys(), dtype=salary_dtype, na_values=['?'])\n",
    "salary_test = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test', sep=', ', engine='python', skiprows=[0], names=salary_dtype.keys(), dtype=salary_dtype, na_values=['?'])\n",
    "salary_train_X, salary_train_Y = salary_data.iloc[:,:len(salary_dtype)-1], salary_data['target']\n",
    "salary_test_X, salary_test_Y = salary_test.iloc[:,:len(salary_dtype)-1], salary_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations catégorie -> one-hot\n",
    "identity = lambda x: x\n",
    "cat_to_codes = lambda x: x.cat.codes\n",
    "salary_transform = {\n",
    "    'age': identity,\n",
    "    'workclass': cat_to_codes,\n",
    "    'financial_weight': identity,\n",
    "    'education': cat_to_codes,\n",
    "    'marital_status': cat_to_codes,\n",
    "    'occupation': cat_to_codes,\n",
    "    'relationship': cat_to_codes,\n",
    "    'race': cat_to_codes,\n",
    "    'sex': cat_to_codes,\n",
    "    'capital_gain': identity,\n",
    "    'capital_loss': identity,\n",
    "    'hours_per_week': identity,\n",
    "    'native_country': cat_to_codes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise un état déterministe pour la routine `train_test_split` afin de s'assurer de ne jamais toucher l'ensemble de test avant la toute fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = fetch_mldata('mnist-original')\n",
    "mnist_train_X, mnist_test_X, mnist_train_Y, mnist_test_Y = train_test_split(mnist_data['data'], mnist_data['target'], random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieur de Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salary\n",
    "\n",
    "Pour classer les features catégoriques du dataset de salaires, on les convertit en one-hot et on utilise un classifier naïf ad-hoc avec densité de Bernouilli. On considère ensuite la probabilité suivante: $\\Pr [c \\mid x_{cont},x_{cat}] = \\frac{\\Pr[X_{cont} X_{cat} \\mid c]\\Pr[c]}{\\Pr[X_{cont}] \\Pr[X_{cat}]}$.\n",
    "\n",
    "Avec l'hypothèse naïve $\\Pr[X_{cont},X_{cat}] = \\Pr[X_{cont}] \\Pr[X_{cat}]$ et en passant par le logarithme:\n",
    "\n",
    "$\\implies \\log \\Pr[X_{cont} \\mid c] + \\log \\Pr[X_{cat} \\mid c] + \\log \\Pr[c] - (\\log \\Pr[X_{cont}] + \\log \\Pr[X_{cat}])$\n",
    "\n",
    "Si l'on prend la somme des log-probabilité des deux modèles, on compte deux fois les priors $\\Pr[c]$. On remédie à cette situation en le soustrayant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class MixedNB(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Mixed gaussian and binomial-on-onehot naive Bayes classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.gnb = GaussianNB()\n",
    "        self.bnb = BernoulliNB(alpha)\n",
    "        self.encoder = OneHotEncoder()\n",
    "    def get_params(self, deep=False):\n",
    "        return {'alpha': self.alpha}\n",
    "    def set_params(self, **parameters):\n",
    "        for name, val in parameters.items():\n",
    "            setattr(self, name, val)\n",
    "        self.bnb.set_params(alpha=self.alpha)\n",
    "        return self\n",
    "    def fit(self, X, y):\n",
    "        cat_as_codes = X[salary_categorical_columns].transform(lambda x: x.cat.codes + 1)\n",
    "        self.encoder.fit(cat_as_codes)\n",
    "        self.gnb.fit(X[salary_continuous_columns], y)\n",
    "        self.bnb.fit(self.encoder.transform(cat_as_codes), y)\n",
    "    def predict(self, X):\n",
    "        cat_as_codes = X[salary_categorical_columns].transform(lambda x: x.cat.codes + 1)\n",
    "        lp = self.gnb.predict_log_proba(X[salary_continuous_columns]) + self.bnb.predict_log_proba(self.encoder.transform(cat_as_codes)) - self.bnb.class_log_prior_\n",
    "        return self.gnb.classes_[np.argmax(lp, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_salary = GridSearchCV(MixedNB(), param_grid={'alpha': np.logspace(-1, 2)}, scoring='accuracy', n_jobs=16, return_train_score=True)\n",
    "mnb_salary.fit(salary_train_X, salary_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(mnb_salary.cv_results_)\n",
    "plt.plot(r.param_alpha, 1 - r.mean_train_score, label='Entraînement')\n",
    "plt.plot(r.param_alpha, 1 - r.mean_test_score, label='Validation')\n",
    "plt.title('Courbe d\\'apprentissage sur salary')\n",
    "plt.xlabel('Lissage laplacien')\n",
    "plt.ylabel('Erreur')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_mnist = GaussianNB()\n",
    "1 - cross_val_score(gnb_mnist, mnist_train_X, mnist_train_Y, scoring='accuracy', n_jobs=16).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_param_grid = {'max_depth': range(1, 20)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtc_salary = GridSearchCV(DecisionTreeClassifier(), param_grid=dtc_param_grid, scoring='accuracy', n_jobs=16, return_train_score=True)\n",
    "dtc_salary.fit(salary_train_X.transform(salary_transform), salary_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(dtc_salary.cv_results_)\n",
    "plt.plot(r.param_max_depth, 1 - r.mean_train_score, label='Entraînement')\n",
    "plt.plot(r.param_max_depth, 1 - r.mean_test_score, label='Validation')\n",
    "plt.title('Courbe d\\'apprentissage sur salary')\n",
    "plt.xlabel('Profondeur maximale')\n",
    "plt.ylabel('Erreur')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtc_mnist = GridSearchCV(DecisionTreeClassifier(), param_grid=dtc_param_grid, scoring='accuracy', n_jobs=16, return_train_score=True)\n",
    "dtc_mnist.fit(mnist_train_X, mnist_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(dtc_mnist.cv_results_)\n",
    "plt.plot(r.param_max_depth, 1 - r.mean_train_score, label='Erreur d\\'entraînement')\n",
    "plt.plot(r.param_max_depth, 1 - r.mean_test_score, label='Erreur de validation')\n",
    "plt.title('Courbe d\\'apprentissage sur MNIST')\n",
    "plt.xlabel('Profondeur maximale')\n",
    "plt.ylabel('Erreur')\n",
    "plt.xticks(range(1, 20))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbres de décisions + classifieurs de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle boosté"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron multi-couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=28*28, input_dim=28*28))\n",
    "model.add(Dense(units=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy, optimizer=SGD(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(mnist_train_X, mnist_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.zeros(shape=(1, 784)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de neurones convolutif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "Ici, on trouve le code pour les tests finaux qui ont été effectués à la toute fin, indépendament du processus de validation afin d'avoir la meilleure idée possible de la performance de généralisation de chaque modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2",
   "language": "python",
   "name": "python3.6.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
